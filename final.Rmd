---
title: "IODS Final Assignment"
author: "Henna Kettunen"
email: "henna.kettunen@kapsi.fi"
date: "3 maaliskuuta 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Abstract

This is a report for the final assignment of IODS course. 


## Research question

Can we use mutinomial logistic regression to identify tropical tree genera based on observed leaf and stem traits?


## Data description

The data set used in this assignment is an extract of the BRIDGE database for leaf and stem traits collected from French Guiana. There are data on (at least) 646 different tropical tree species belonging to 222 genera and 59 families in this data set. 

Reference to data package:
Paine CET, Baraloto C, Diaz S (2015) Selected leaf and stem traits from the BRIDGE database. 

Data from: Optimal strategies for sampling functional traits in species-rich forests. TRY Downloadable Files Archive https://www.try-db.org/TryWeb/Data.php#7

The data include the following 18 variables that describe leaf and stem traits:
```
Field name                  Description
Family                      Plant family
Genus                       Plant genus
species                     Plant species
bar_code                    Unique identifier for each individual in the Bridge db
plot_code                   Plot identification in the Bridge database
X                           X coordinate of position of individual in the plot (in meter)
Y                           Y coordinate of position of individual in the plot (in meter)
DBH                         Tree diameter at breast height (cm)
leaf_thickness              Leaf thickness (micro m)
leaf_toughness              Leaf toughness, measured by penetrometer (Newton)
sapwood_density             Sapwood density (g/cm3)
N                           Leaf nitrogen concentration (g/g)
C_N                         Leaf carbon/nitrogen ratio 
N15                         Leaf delta Nitrogen 15 concentration (per mill)
C13                         Leaf delta Carbon 13 concentration (per mill)
chlorophyll_concentration   Leaf chlorophyll concentration (micro g/mm2)
surface_area                Leaf surface area (cm2)
SLA                         Specific leaf area (mm2/g)
```

Thanks to PhD [jtuimala](https://jtuimala.github.io/IODS-final/) for pointing out this data set to me. (After reading his final report, one has to wonder if PhD actually stands for Pok√©mon-hunting Doctor.)
```{r read-in, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
library(tidyr)
library(dplyr)

# Tropical tree leaf data from BRIDGE database obtained via TRY
trees <- read.csv("trees.csv")

# Combine genus and species to a same column
trees$name <- paste0(trees$Genus, "_", trees$species)

# How many families? 59
famn <- summarise(trees, nfam=n_distinct(Family))

# How many genera? 222
genn <- summarise(trees, nfam=n_distinct(Genus))

# How many species? 646
specn <- summarise(trees, nfam=n_distinct(name))
```


## Data manipulation

First, I created a new variable `name`, which combines genus and species to a same column, and eases with calculating summaries on species-level. I had an intent to analyse the data on species-level, but it turned out that there were generally only several observations per species, and no species with more than 31 complete observations. This hardly provides the amount of variation necessary for most statistical methods. Imputing might have helped with the missing observations, but as I am no expert on that topic, I decided to use the complete cases only. (Suggestion: maybe you could introduce imputing as an IODS course topic next year, please?)
```{r specn, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
# Combine genus and species to a same column
trees$name <- paste0(trees$Genus, "_", trees$species)

# How many observations per species?
nobs <- count(trees[complete.cases(trees)==T,], name)
nobs <- arrange(nobs, desc(n))
nobs[1:10,]
```

Therefore, I changed the focus to genus-level, and found out that there are six genera with at least 50 complete observations in the data. These belong to four different plant families, and comprise 107 different species. I limited the data to these six genera, included only the complete cases, and removed variables `Family`, `species`, `bar_code`, `plot_code`, `X`, `Y` and `name` from the limited data. Hence, I ended up with 12 variables and 520 rows of data. All the remaining variables were numerical and continuous, except `Genus`, which was categorical. I didn't standardize the variables, as regression models are easier to interpret if fitted on unstandardized data.
```{r genn, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
# How many observations per genus?
nobsg <- trees[complete.cases(trees),] %>% group_by(Genus) %>% summarise(nobs=n())
nobsg <- arrange(nobsg, desc(nobs))

# Genera with >= 50 observations
gen50 <- nobsg[which(nobsg$nobs>=50),]
gen50 <- gen50[gen50$Genus!="IND",]

# How many observations?
fam50 <- unique(trees[trees$Genus %in% gen50$Genus, c("Family","Genus")])
fam50$n.obs <- gen50$nobs[match(fam50$Genus, gen50$Genus)]

# 6 genera with >=50 complete cases belonging to 4 different families selected for further analyses
dat <- trees[complete.cases(trees) & trees$Genus %in% gen50$Genus,]
specn2 <- length(unique(dat$name))

# Number of species per genus
nspec2 <- dat %>% group_by(Genus) %>% summarise(nspec=n_distinct(species))
fam50$n.spec <- nspec2$nspec[match(fam50$Genus, nspec2$Genus)]
fam50

# Drop unnecessary variables
keep <- c("Genus","DBH","leaf_thickness","leaf_toughness","sapwood_density","N","C_N","N15","C13","chlorophyll_concentration","surface_area","SLA")
dat <- dat[,keep]
```

The code for data wrangling can be found [here](wrangle.r).


## Explorative analysis

```{r exp1, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
# Summary
summary(dat)

# Histograms
library(reshape2)
library(ggplot2)
mdat <- melt(dat)
ggplot(mdat, aes(value)) + geom_histogram(fill="red") + facet_wrap(~ variable, scales="free")
```

The histograms show that most variables in the scaled data are unimodal, but there are some (`leaf_toughness`, `N` and `C13`) that are slightly multimodal (but this can depend on the binwidth of histograms). Variables `DBH`, `leaf_thickness`, `N`, `C_N`, `chlorophyll_concentration`, `surface_area` and `SLA` are clearly skewed to right, and `sapwood_density` is skewed to left. No variable seems to be exactly normally distributed.

```{r exp2, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
# Correlation matrix
library(corrplot)
cor_matrix <- cor(dat[,2:ncol(dat)]) 
corrplot(cor_matrix, method="circle", type="upper", cl.pos="b", tl.pos="d", tl.cex=0.6)
```

The correlation matrix reveals that there are high correlations between variables `leaf thickness` and `leaf toughness`, `N` and `C_N`, and `leaf_thickness` and `SLA`. This may cause a multicollinearity problem in the analysis, so we drop one variable from each pair. `C_N` is a derivative variable calculated from `N`, and thus can be dropped. Also `SLA` might be best to drop, as it correlates with many other variables. There is no clear data-based indication for which one to keep of the variable pair `leaf_thickness` and `leaf_toughness`, but I chose to drop the latter one. Now the data consist of 9 variables.
```{r exp3, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE, fig.width=10, fig.height=10}
# Drop correlated variables
drop <- c("leaf_toughness", "C_N", "SLA")
dat <- dat[,!colnames(dat) %in% drop]
dat$Genus <- droplevels(dat$Genus)

# Scatterplot matrix
pairs(dat, cex=0.5, pch=16, col=dat$Genus)
```

No variable alone seems to identificate different genera in the pairplot, but the data is highly multidimensional, and a combination of variables might provide better classification results.


## Multinomial logistic regression

Multinomial logistic regression is a classification method, which generalizes logistic regression to multiclass classification problems, i.e. settings with more than two possible outcome classes. The advantage of multinomial logistic regression compared to another multiclass classification method, linear discriminant analysis (LDA), is that the multinomial logistic regression model can include both numerical and categorical predictor variables, whereas LDA only can include continuous numerical predictors. All possible predictors in my data were actually continuous, but I wanted to give a try to multinomial model, as I had never tried it earlier. 

There are at least two possible functions to fit multinomial logistic regression model with in R: function `multinom()` from package `nnet`, and function `mlogit()` from package `mlogit`. I chose the former one, which accepts data in a wide format. The latter one requires the data to be reshaped to a long format. Before starting with multinomial modelling, I divided the data to mutually exclusive train and test sets of equal size. In the code below, this division was frozen to an earlier run to ensure that the results correspond to ones presented in the following text.

```{r mult1, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
# Divide to training and test sets
# ind <- sample(nrow(dat), nrow(dat)*0.5)
# save(ind, file="ind.RData")
load("ind.RData")
train <- dat[ind,]
test <- dat[-ind,]
```

The first model I fitted (Model 1) was a model with all possible predictor variables included. For simplicity, I only considered the main effects model with no polynomial terms. 
```{r mult2, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE, results="hide"}
# Full main effects model
library(nnet)
fit1 <- multinom(Genus ~ ., data = train)

```

There is a high chance that a model fitted with a high number of predictor variables will overparametrized, which means that the model predicts well the training data, but generalizes poorly to new data. To avoid overfitting, I utilized a backward model selection algorithm. Selection algorithms are generally regarded as a quick-and-dirty solution to model selection, but I didn't have the time and skills necessary for using more sophisticated methods. The idea of backward selection is to minimize the AIC value (Akaike information criterion) by dropping uninformative predictor variables from the model. AIC is a likelihood-based goodness-of-fit measure, which compares a collection of models relative to each other. Hence, an absolute AIC value tells us not much about goodness of fit, but a lower AIC relative to a higher one means a better-fitting model.
```{r mult3, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE, results="hide"}
# Model selection
library(MASS)
step <- stepAIC(fit1, direction="backward")
```

The best model chosen by backward selection includes six predictor variables: Genus ~ Intercept + leaf_thickness + sapwood_density + N + C13 + chlorophyll_concentration + surface_area. Let's fit this model as Model 2, and give a closer look at the results.
```{r mult4, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE, results="hide"}
# Best model according to AIC
fit2 <- multinom(Genus ~ leaf_thickness + sapwood_density + N + C13 + chlorophyll_concentration + surface_area, data = train)
aic <- AIC(fit1, fit2)
summary(fit2)
```

The AIC of Model 2 is 657.8, which is clearly lower compared to Model 1 (AIC = 669.9). We can see from the summary table that the model coefficients are estimated for each variable per class combination except for genus *Eschweilera*, which is selected as a reference class and not shown in the table. In a multinomial model with k response classes, we estimate k - 1 separate logistic regression models. The probability in each model is always calculated relative to the reference class. So for Model 2 we actually have five model equations:

```
(1) ln (p1 / p6) = -6.4 + 0.009 x lea_thi - 4.7 x sap_den + 95.4 x N - 0.22 x C13 - 0.022 x chl_con - 0.003 x sur_are
(2) ln (p2 / p6) = -36.1 + 0.015 x lea_thi + 13.4 x sap_den - 49.6 x N - 0.90 x C13 - 0.045 x chl_con - 0.041 x sur_are
(3) ln (p3 / p6) = -8.6 + 0.012 x lea_thi - 10.3 x sap_den - 2.4 x N - 0.49 x C13 - 0.026 x chl_con - 0.028 x sur_are
(4) ln (p4 / p6) = -23.9 + 0.004 x lea_thi + 8.4 x sap_den + 120.4 x N - 0.55 x C13 - 0.013 x chl_con - 0.016 x sur_are
(5) ln (p1 / p6) = 10.0 - 0.020 x lea_thi - 17.0 x sap_den - 230.5 x N - 0.31 x C13 - 0.002 x chl_con - 0.003 x sur_are
```

where p1 is the probability for *Lecythis*, p2 for *Licania*, p3 for *Micropholis*, p4 for *Pouteria*, p5 for *Protium* and p6 for *Eschweilera*.

But how do we estimate the probability for genus *Eschweilera*, which is used as a reference? From the fact that the estimated probabilities across all genera evidently sum up to 1, we can derive the following probability formula for *Eschweilera*:

```
(6) p6 = 1 / (1 + exp(eq. 1) + exp(eq. 2) + ... + exp(eq. 5))
```

From the equation 1 we can see for example that 

* a one-unit increase in the variable `leaf_thickness` is associated with the increase in the log odds of belonging to genus *Licania* vs. *Eschweilera* by the amount of 0.009
* a one-unit increase in the variable `sapwood_density` is associated with the decrease in the log odds of belonging to genus *Licania* vs. *Eschweilera* by the amount of 4.7

In logistic regression we can express regression coefficients as odd ratios. In multinomial logistic regression we can respectively transform coefficients by exponentiation to relative risk ratios for unit change in a predictor variable.
```{r, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
round(exp(coef(fit2)), 3)
```

Are all predictor variables in Model 2 statistically significant? We can check that with an LR test.
```{r, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
library(car)
Anova(fit2)
```

`C13` and `chlorophyll_concentration` don't seem to be statistically significant predictors for genera, whereas all the other predictors are significant. However, if we fit a third model by dropping the two statistically insignificant variables, the AIC for this model is a bit higher (658.2), implying a lower goodness-of-fit. So let's declare Model 2 as our final model.

Finally, we can visualize Model 2 to get a better picture of predicted probabilities. Library `visreg` provides us a nice tool for this.
```{r, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE, fig.width=8, fig.height=6}
library(visreg)
visreg(fit2, xvar="leaf_thickness", collapse=T, type="conditional")
```


## Model validation

How accurately do the fitted models classify new cases, and are there differences in their classification performance? Let's see and predict the test data with our models.
```{r, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
# Model 1
pred1 <- predict(fit1, newdata=test)
genus <- test$Genus
tab <- table(pred=pred1, obs=genus)
tab2 <- as.data.frame(tab)
# Correct rate
cor1 <- sum(tab2$Freq[tab2$pred==tab2$obs])/nrow(test)

# Model 2
pred2 <- predict(fit2, newdata=test)
pred2p <- as.data.frame(fitted(fit2))
tab3 <- table(pred=pred2, obs=genus)
tab4 <- as.data.frame(tab3)
# Correct rate
cor2 <- sum(tab4$Freq[tab4$pred==tab4$obs])/nrow(test)
```

The second model correctly predicts genus in 50.3 % of test cases, which is slightly better than for the first model (47 %). Note however that this can actually depend on how we divide the data into training and test sets. A better way of determining the error rate for different models would be by crossvalidation, but the function cv.glm() we used in an earlier assignment to perform crossvalidation can't handle multinomial logistic models, so I didn't crossvalidate here. 

Next, it would be useful to check if Model 2 classifies all genera with an equal accuracy.
```{r, echo=TRUE, warning=FALSE, error=FALSE, message=FALSE}
tab3
round(prop.table(tab3, 2), 3)
```

From the confusion matrix we can see that the model correctly classifies 92 % of *Protiums* and 69 % of *Pouterias*, but only 10 % of *Lecythises* and 11 % of *Eschweileras*. (These percentages are for true positive outcomes.) The model confuses the two latter genera to *Pouteria*, which is the most frequent genus in the test data. Also *Licania* and *Micropholis* are frequently confused with *Pouteria*. Obviously the model overestimates the frequency of *Protium* and *Pouteria* at the expense of other genera. In any case, both models are in overall significantly better classificators than a simple strategy of guessing all trees to belong to genus *Pouteria*, which is the most common genus in the test data with 28.5 % cases.

Multinomial logistic regression assumes independence of irrelevant alternatives (IIA), which means that te characteristics of one particular choice alternative (class) do not impact the relative probabilities of choosing other alternatives (classes). IIA can be tested e.g. by (Hausman-McFadden test)[http://finzi.psych.upenn.edu/library/mlogit/html/hmftest.html], but I ran out of time for testing IIA.



